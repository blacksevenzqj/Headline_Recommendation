{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/toutiao_project\n",
      "['/root/toutiao_project/reco_sys', '/root/toutiao_project', '/root/toutiao_project', '/miniconda2/envs/reco_sys/lib/python35.zip', '/miniconda2/envs/reco_sys/lib/python3.5', '/miniconda2/envs/reco_sys/lib/python3.5/plat-linux', '/miniconda2/envs/reco_sys/lib/python3.5/lib-dynload', '', '/miniconda2/envs/reco_sys/lib/python3.5/site-packages', '/miniconda2/envs/reco_sys/lib/python3.5/site-packages/IPython/extensions', '/root/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# 如果当前代码文件运行测试需要加入修改路径，避免出现后导包问题\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR, 'reco_sys'))\n",
    "print(BASE_DIR)\n",
    "print(sys.path)\n",
    "\n",
    "PYSPARK_PYTHON = \"/miniconda2/envs/reco_sys/bin/python\"\n",
    "# 当存在多个版本时，不指定很可能会导致出错\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYSPARK_PYTHON\n",
    "\n",
    "from offline import SparkSessionBase\n",
    "import pyhdfs\n",
    "import time\n",
    "\n",
    "\n",
    "class UpdateUserProfile(SparkSessionBase):\n",
    "    \"\"\"离线相关处理程序\n",
    "    \"\"\"\n",
    "    SPARK_APP_NAME = \"updateUser\"\n",
    "    SPARK_URL = \"local\"\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "\n",
    "    SPARK_EXECUTOR_MEMORY = \"1g\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.spark = self._create_spark_session()\n",
    "\n",
    "uup = UpdateUserProfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+---------+--------------------+----------------+--------+-------------------+\n",
      "|         actionTime|readTime|channelId|           articleId|algorithmCombine|  action|             userId|\n",
      "+-------------------+--------+---------+--------------------+----------------+--------+-------------------+\n",
      "|2019-04-02 12:21:55|        |        0|[44737, 44739, 14...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:21:57|        |       18|              140357|              C2|   click|1112727762809913344|\n",
      "|2019-04-02 12:22:20|        |       18|              140357|              C2| collect|1112727762809913344|\n",
      "|2019-04-02 12:22:36|   38000|       18|              140357|              C2|    read|1112727762809913344|\n",
      "|2019-04-02 12:22:43|        |       18|               13476|              C2|   click|1112727762809913344|\n",
      "|2019-04-02 12:23:08|   23306|       18|               13476|              C2|    read|1112727762809913344|\n",
      "|2019-04-02 12:23:13|        |        0|[14805, 15196, 44...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:23:16|        |        0|[18795, 18156, 43...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:21:55|        |        0|[44737, 44739, 14...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:21:57|        |       18|              140357|              C2|   click|1112727762809913344|\n",
      "|2019-04-02 12:22:20|        |       18|              140357|              C2| collect|1112727762809913344|\n",
      "|2019-04-02 12:22:36|   38000|       18|              140357|              C2|    read|1112727762809913344|\n",
      "|2019-04-02 12:22:43|        |       18|               13476|              C2|   click|1112727762809913344|\n",
      "|2019-04-02 12:23:08|   23306|       18|               13476|              C2|    read|1112727762809913344|\n",
      "|2019-04-02 12:23:13|        |        0|[14805, 15196, 44...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:23:16|        |        0|[18795, 18156, 43...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:21:55|        |        0|[44737, 44739, 14...|              C2|exposure|1112727762809913344|\n",
      "|2019-04-02 12:21:57|        |       18|              140357|              C2|   click|1112727762809913344|\n",
      "|2019-04-02 12:22:20|        |       18|              140357|              C2| collect|1112727762809913344|\n",
      "|2019-04-02 12:22:36|   38000|       18|              140357|              C2|    read|1112727762809913344|\n",
      "+-------------------+--------+---------+--------------------+----------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# - 2、读取固定时间内的用户行为日志\n",
    "uup.spark.sql(\"use profile\")\n",
    "user_action = uup.spark.sql(\"select actionTime, readTime, channelId, param.articleId, param.algorithmCombine, param.action, param.userId from user_action where dt>='2019-04-01'\")\n",
    "user_action.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+----------+------+-------+---------+--------+---------+\n",
      "|            user_id|        action_time|article_id|channel_id|shared|clicked|collected|exposure|read_time|\n",
      "+-------------------+-------------------+----------+----------+------+-------+---------+--------+---------+\n",
      "|1103195673450250240|2019-04-10 06:00:20|    141440|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44161|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17283|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     43907|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     16005|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     15750|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44419|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     14225|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17304|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|    134812|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:25|     44161|        18| false|   true|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|    141440|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44161|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17283|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     43907|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     16005|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     15750|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44419|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     14225|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17304|         0| false|  false|    false|    true|         |\n",
      "+-------------------+-------------------+----------+----------+------+-------+---------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# - 3、进行用户日志数据处理\n",
    "def _compute(row):\n",
    "    \n",
    "    _list = []\n",
    "    if row.action == 'exposure':\n",
    "        for article_id in eval(row.articleId):\n",
    "            # 用户ID跟文章ID拼接一个样本\n",
    "            # [\"user_id\", \"action_time\",\"article_id\", \"channel_id\", \"shared\", \"clicked\", \"collected\", \"exposure\", \"read_time\"]\n",
    "            _list.append([row.userId, row.actionTime, article_id, row.channelId, False, False, False, True, row.readTime])\n",
    "        return _list\n",
    "    else:\n",
    "        class Temp(object):\n",
    "            shared = False\n",
    "            clicked = False\n",
    "            collected = False\n",
    "            read_time = \"\"\n",
    "        \n",
    "        _tp = Temp()\n",
    "        if row.action == 'click':\n",
    "            _tp.clicked = True\n",
    "        elif row.action == 'share':\n",
    "            _tp.shared = True\n",
    "        elif row.action == 'collect':\n",
    "            _tp.collected = True\n",
    "        elif row.action == 'read':\n",
    "            _tp.clicked = True\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        _list.append([row.userId, row.actionTime, int(row.articleId), row.channelId, _tp.shared, _tp.clicked, _tp.collected, True, row.readTime])\n",
    "        \n",
    "        return _list\n",
    "        \n",
    "\n",
    "_res = user_action.rdd.flatMap(_compute)\n",
    "user_action_basic = _res.toDF([\"user_id\", \"action_time\",\"article_id\", \"channel_id\", \"shared\", \"clicked\", \"collected\", \"exposure\", \"read_time\"])\n",
    "user_action_basic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、行为表：行为需要更更新\n",
    "2、将新的行为数据与历史行为数据进⾏合并\n",
    "3、按照用户ID与文章ID分组合并，合并成⼀一行数据\n",
    "4、HIVE目前支持hive终端操作ACID, update, delete\n",
    "5、不支持python的pyspark原⼦性操作，并且开启配置中开启原⼦性相关配置也不行。insert overwrit\n",
    "6、删除原来的表数据，将所有数据重新插⼊\n",
    "'''\n",
    "# 合并历史数据，存储到user_article_basic表中\n",
    "old = uup.spark.sql(\"select * from user_article_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+----------+------+-------+---------+--------+---------+\n",
      "|            user_id|        action_time|article_id|channel_id|shared|clicked|collected|exposure|read_time|\n",
      "+-------------------+-------------------+----------+----------+------+-------+---------+--------+---------+\n",
      "|1103195673450250240|2019-04-10 06:00:20|    141440|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44161|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17283|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     43907|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     16005|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     15750|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44419|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     14225|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17304|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|    134812|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:25|     44161|        18| false|   true|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|    141440|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44161|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17283|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     43907|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     16005|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     15750|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     44419|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     14225|         0| false|  false|    false|    true|         |\n",
      "|1103195673450250240|2019-04-10 06:00:20|     17304|         0| false|  false|    false|    true|         |\n",
      "+-------------------+-------------------+----------+----------+------+-------+---------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 由于合并的结果中 user_id和article_id 不是唯一的，所以 一个用户 会对 文章 有多种操作\n",
    "new = old.unionAll(user_action_basic)\n",
    "new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIVE目前支持hive终端操作ACID，不支持python的pyspark原子性操作，并且开启配置中开启原子性相关配置也不行。所以只能通过如下方式更新：\n",
    "# insert overwrite table... 删除原来的表数据，将所有数据重新插⼊\n",
    "\n",
    "# new.registerTempTable('temptable')\n",
    "\n",
    "# max(Boolean)：true默认为1；false默认为0。所以max(Boolean)时，如果有true，则取true。\n",
    "# uup.spark.sql(\"insert overwrite table user_article_basic select user_id, max(action_time) as action_time, \"\n",
    "#         \"article_id, max(channel_id) as channel_id, max(shared) as shared, max(clicked) as clicked, \"\n",
    "#         \"max(collected) as collected, max(exposure) as exposure, max(read_time) as read_time from temptable \"\n",
    "#         \"group by user_id, article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+------+-------+---------+--------+---------+\n",
      "|            user_id|        action_time|article_id|shared|clicked|collected|exposure|read_time|\n",
      "+-------------------+-------------------+----------+------+-------+---------+--------+---------+\n",
      "|1105045287866466304|2019-03-11 18:13:45|     14225| false|  false|    false|    true|         |\n",
      "|1106476833370537984|2019-03-15 16:46:50|     14208| false|  false|    false|    true|         |\n",
      "|1111189494544990208|2019-03-28 17:02:35|     19322| false|  false|    false|    true|         |\n",
      "|1111524501104885760|2019-03-29 15:04:27|     44161| false|  false|    false|    true|         |\n",
      "|1112727762809913344|2019-04-03 12:51:57|     18172| false|   true|     true|    true|    19413|\n",
      "|                  1|2019-03-07 16:57:34|     44386| false|   true|    false|    true|    17850|\n",
      "|                  1|2019-03-11 18:13:11|     44696| false|  false|    false|    true|         |\n",
      "|                 10|2019-03-06 10:06:15|     43907| false|  false|    false|    true|         |\n",
      "|1106473203766657024|2019-03-15 16:32:24|     16005| false|  false|    false|    true|         |\n",
      "|1108264901190615040|2019-03-20 15:18:27|     15196| false|  false|    false|    true|         |\n",
      "|                 23|2019-04-03 08:10:23|     44739| false|   true|    false|    true|    14216|\n",
      "|                 33|2019-03-06 18:24:11|     13570| false|  false|    false|    true|         |\n",
      "|                  1|2019-03-15 16:42:42|     17632| false|  false|    false|    true|         |\n",
      "|1106473203766657024|2019-03-15 16:32:24|     17665| false|  false|    false|    true|         |\n",
      "|1111189494544990208|2019-03-28 16:57:45|     44368| false|  false|    false|    true|         |\n",
      "|                 10|2019-03-06 10:06:15|     44368| false|  false|    false|    true|         |\n",
      "|1105093883106164736|2019-03-11 21:11:33|     15750| false|  false|    false|    true|         |\n",
      "|1106396183141548032|2019-03-28 10:55:34|     19476| false|  false|    false|    true|         |\n",
      "|1111524501104885760|2019-03-29 15:04:54|     19233| false|  false|    false|    true|         |\n",
      "|                  2|2019-03-05 10:19:54|     44371| false|   true|    false|    true|      938|\n",
      "+-------------------+-------------------+----------+------+-------+---------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.2.2.3 用户画像频道主题词获取 与 权重计算\n",
    "# 目标：获取用户1~25频道(不包括 推荐频道0)的关键词，并计算权重（以 章画像表article_profile 的频道字段channel_id为准）\n",
    "\n",
    "# 1、合并 用户行为表user_article_basic  与  文章画像表article_profile（通过文章ID字段：article_id 合并）\n",
    "# 1.1、读取 用户行为表user_article_basic \n",
    "# 删除用户行为表user_article_basic中的channel_id字段的原因：用户行为表中的频道号，是通过Web后台进行埋点，有些并没有真正对应文章所属频道\n",
    "# (因为有些文章是通过 推荐显示的文章：推荐频道为0号频道，下拉页面获取推荐曝光文章列表时 埋点会将文章对应的频道在日志中记录为0频道)\n",
    "uup.spark.sql(\"use profile\")\n",
    "user_basic = uup.spark.sql(\"select * from user_article_basic\").drop('channel_id')\n",
    "user_basic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|              topics|\n",
      "+----------+----------+--------------------+\n",
      "|        26|        17|[Electron, 全自动, 产...|\n",
      "|        29|        17|[WebAssembly, 影音,...|\n",
      "|       474|        17|[textAlign, borde...|\n",
      "|       964|        11|[protocol, RMI, d...|\n",
      "|      1677|        17|[spritesmith, ico...|\n",
      "|      1697|         6|[nav, 样式, width, ...|\n",
      "|      1806|        17|[声明, word, 容器, Ex...|\n",
      "|      1950|        17|[app, scss, koala...|\n",
      "|      2040|        17|[宽度, 媒体, width, r...|\n",
      "|      2214|        11|[Cyber, 语言, 黑客, 知...|\n",
      "|      2250|         6|[宽度, cal, 阶梯, 页面,...|\n",
      "|      2453|        13|[__, CNN, logisti...|\n",
      "|      2509|        13|[池化, CNN, 卷积神经网络,...|\n",
      "|      2529|        17|[标题栏, 定义, 嵌套, hea...|\n",
      "|      2927|         6|[季风, 圆角, bezier, ...|\n",
      "|      3091|         6|[Chrome, react, 工...|\n",
      "|      3506|        17|[cond, AJAX, 实心, ...|\n",
      "|      3764|        15|[__, 语言, 原型链, obj...|\n",
      "|      4590|        19|[println, Class, ...|\n",
      "|      4823|        19|[引用传递, Human, TOD...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.2、读取 文章画像表article_profile\n",
    "uup.spark.sql(\"use article\")\n",
    "article_topic = uup.spark.sql(\"select  article_id, channel_id, topics from article_profile\")\n",
    "article_topic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+------+-------+---------+--------+---------+----------+--------------------+\n",
      "|         article_id|            user_id|        action_time|shared|clicked|collected|exposure|read_time|channel_id|              topics|\n",
      "+-------------------+-------------------+-------------------+------+-------+---------+--------+---------+----------+--------------------+\n",
      "|              13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|[补码, 字符串, 李白, typ...|\n",
      "|              13401|1106396183141548032|2019-03-28 10:58:20| false|  false|    false|    true|         |        18|[补码, 字符串, 李白, typ...|\n",
      "|              14805|1105045287866466304|2019-03-11 18:15:48| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|                  1|2019-03-05 17:34:03| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1111524501104885760|2019-03-29 15:05:28| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1111189494544990208|2019-03-28 16:57:45| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1106476833370537984|2019-03-15 16:48:08| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|                 38|2019-03-07 19:11:11| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1108264901190615040|2019-03-20 15:18:27| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1112727762809913344|2019-04-03 12:50:40| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1106396183141548032|2019-03-28 10:54:28| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|                 10|2019-03-06 10:06:15| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|                  2|2019-03-05 10:20:47| false|   true|    false|    true|      671|        18|[占位符, Code, sep, ...|\n",
      "|              14805|1103195673450250240|2019-03-20 22:43:38| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1106473203766657024|2019-03-15 22:22:15| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|1105105185656537088|2019-03-11 22:00:14| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|              14805|                 23|2019-03-05 16:31:37| false|  false|    false|    true|         |        18|[占位符, Code, sep, ...|\n",
      "|1112593324574769152|1113244157343694848|2019-04-03 08:57:46| false|  false|    false|    true|         |      null|                null|\n",
      "|1112593324574769152|1113316420155867136|2019-04-03 13:44:54| false|  false|    false|    true|         |      null|                null|\n",
      "|              44013|1106396183141548032|2019-03-29 13:56:24| false|  false|    false|    true|         |        18|[frozenset, 字典, 无...|\n",
      "+-------------------+-------------------+-------------------+------+-------+---------+--------+---------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_topic = user_basic.join(article_topic, on=['article_id'], how='left')\n",
    "user_topic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+------+-------+---------+--------+---------+----------+--------+\n",
      "|article_id|            user_id|        action_time|shared|clicked|collected|exposure|read_time|channel_id|   topic|\n",
      "+----------+-------------------+-------------------+------+-------+---------+--------+---------+----------+--------+\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      补码|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|     字符串|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      李白|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|    type|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      元素|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|    删除元素|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      负数|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      基数|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|     tp2|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|    数据类型|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|     二进制|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|xiaoming|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      大写|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      示例|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      字典|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|     八进制|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|      元组|\n",
      "|     13401|                 10|2019-03-06 10:06:12| false|  false|    false|    true|         |        18|   print|\n",
      "|     13401|1106396183141548032|2019-03-28 10:58:20| false|  false|    false|    true|         |        18|      补码|\n",
      "|     13401|1106396183141548032|2019-03-28 10:58:20| false|  false|    false|    true|         |        18|     字符串|\n",
      "+----------+-------------------+-------------------+------+-------+---------+--------+---------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# user_article_basic表 之前经过groupby后 是唯一行。\n",
    "# 将 原topics字段（数组）爆炸/展开 后，如：article_id:13401, user_id:10 的一行数据 展开为 topics数组长度18 的 18行数据。\n",
    "user_topic = user_topic.withColumn('topic', F.explode('topics')).drop('topics')\n",
    "user_topic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.2.4 用户画像之标签权重算法\n",
    "# 用户标签权重 =( 行为类型权重之和) × 时间衰减\n",
    "# 创建HBASE的user_profile表：create 'user_profile', 'basic', 'partial', 'env'\n",
    "def compute_user_label_weights(partitions):\n",
    "    \"\"\"# 计算用户关键词权重\n",
    "    \"\"\"\n",
    "    weightsOfaction = {\n",
    "        \"read_min\": 1,\n",
    "        \"read_middle\": 2,\n",
    "        \"collect\": 2,\n",
    "        \"share\": 3,\n",
    "        \"click\": 5\n",
    "    }\n",
    "    \n",
    "    # 导入包\n",
    "    import happybase\n",
    "    from datetime import datetime\n",
    "    import numpy as np\n",
    "    import json\n",
    "    #  用于读取hbase缓存结果配置（需要开启HBase的Thrift服务：hbase-daemon.sh start thrift）\n",
    "    pool = happybase.ConnectionPool(size=10, host='192.168.19.137', port=9090)\n",
    "    \n",
    "    \n",
    "    # 循环每个用户对应每个关键词处理\n",
    "    for row in partitions:\n",
    "        \n",
    "        # 计算时间系数\n",
    "        t = datetime.now() - datetime.strptime(row.action_time, '%Y-%m-%d %H:%M:%S')\n",
    "        # 时间衰减：1/(log(t)+1) ,t为时间发生时间距离当前时间的大小。\n",
    "        # np.log(t.days + 1) 防止 t.days 为 0。\n",
    "        alpha = 1 / (np.log(t.days + 1) + 1)\n",
    "        \n",
    "        # 判断一下这个关键词对应的操作文章时间大小的权重处理\n",
    "        if row.read_time  == '':\n",
    "            read_t = 0\n",
    "        else:\n",
    "            read_t = int(row.read_time)\n",
    "        \n",
    "        # 阅读时间的行为分数计算出来\n",
    "        read_score = weightsOfaction['read_middle'] if read_t > 1000 else weightsOfaction['read_min']\n",
    "        \n",
    "        # 计算row.topic的权重（false为0，true为1；相当于 0 * X 或 1 * X）\n",
    "        weights = alpha * (row.shared * weightsOfaction['share'] + row.clicked * weightsOfaction['click'] +\n",
    "                          row.collected * weightsOfaction['collect'] + read_score)\n",
    "        \n",
    "        # 保存到HBase的user_profile表中\n",
    "        with pool.connection() as conn:\n",
    "           table = conn.table('user_profile')\n",
    "           table.put('user:{}'.format(row.user_id).encode(),\n",
    "                     {'partial:{}:{}'.format(row.channel_id, row.topic).encode(): json.dumps(weights).encode()})\n",
    "           conn.close()\n",
    "        \n",
    "        \n",
    "user_topic.foreachPartition(compute_user_label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n"
     ]
    }
   ],
   "source": [
    "# 落地Hbase中之后：1、在HBASE中查询user_profile表；2、在HIVE中查询user_profile_hbase（Hbase存储，Hive关联到Hbase）\n",
    "# 1、在HBASE中查询user_profile表（能在HBASE终端  和  pyspark中操作 HBASE表user_profile）\n",
    "import happybase\n",
    "#  用于读取hbase缓存结果配置\n",
    "pool = happybase.ConnectionPool(size=10, host='192.168.19.137', port=9090)\n",
    "\n",
    "with pool.connection() as conn:\n",
    "    table = conn.table('user_profile')\n",
    "    # 获取每个键 对应的所有列的结果\n",
    "    data = table.row(b'user:2', columns=[b'partial'])\n",
    "    print(len(data))\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、在HIVE中查询user_profile_hbase（能在HIVE终端查询；但pyspark中操作报错：Hive关联到Hbase 的 HIVE表user_profile_hbase）\n",
    "# hive> select * from user_profile_hbase limit 1; 正常\n",
    "\n",
    "# uup.spark.sql(\"use profile\")\n",
    "# user_profile_hbase = uup.spark.sql(\"select * from user_profile_hbase limit 1\")\n",
    "# user_profile_hbase.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.3、用户基础信息画像更新（用户的基础信息也需要更新到用户的画像HBASE的user_profile表中）\n",
    "# 是 对象外 的方法：区别于 update_user.py 中的相关代码（对象内方法）。\n",
    "def update_user_info(self):\n",
    "    \"\"\"\n",
    "    更新用户的基础信息画像\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import setting.logging as lg\n",
    "    lg.create_logger()\n",
    "    import logging\n",
    "    logger = logging.getLogger('offline')\n",
    "    from datetime import datetime\n",
    "    \n",
    "    self.spark.sql(\"use toutiao\")\n",
    "    user_basic = self.spark.sql(\"select user_id, gender, birthday from user_profile\")\n",
    "\n",
    "    # 更新用户基础信息\n",
    "    def _udapte_user_basic(partition):\n",
    "        \"\"\"更新用户基本信息\n",
    "        \"\"\"\n",
    "        import happybase\n",
    "        import json\n",
    "        from datetime import datetime\n",
    "        from datetime import date\n",
    "        #  用于读取hbase缓存结果配置\n",
    "        pool = happybase.ConnectionPool(size=10, host='192.168.19.137', port=9090)\n",
    "        for row in partition:\n",
    "            age = 0\n",
    "            if row.birthday != 'null':\n",
    "                born = datetime.strptime(row.birthday, '%Y-%m-%d')\n",
    "                today = date.today()\n",
    "                age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "\n",
    "            with pool.connection() as conn:\n",
    "                table = conn.table('user_profile')\n",
    "                table.put('user:{}'.format(row.user_id).encode(),\n",
    "                          {'basic:gender'.encode(): json.dumps(row.gender).encode()})\n",
    "                table.put('user:{}'.format(row.user_id).encode(),\n",
    "                          {'basic:birthday'.encode(): json.dumps(age).encode()})\n",
    "                conn.close()\n",
    "\n",
    "    user_basic.foreachPartition(_udapte_user_basic)\n",
    "    logger.info(\"{} INFO completely update infomation of basic\".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_user_info(uup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.4 用户画像增量更新定时开启\n",
    "# 看 update_user.py 中的代码。并在 main.py → update.py → update_user.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
