{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark逻辑回归(LR)模型使用介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark配置信息\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "SPARK_APP_NAME = \"preprocessingUserProfile\"\n",
    "SPARK_URL = \"yarn\"\n",
    "\n",
    "conf = SparkConf()    # 创建spark config对象\n",
    "config = (\n",
    "\t(\"spark.app.name\", SPARK_APP_NAME),    # 设置启动的spark的app名称，没有提供，将随机产生一个名称\n",
    "\t(\"spark.executor.memory\", \"2g\"),    # 设置该app启动时占用的内存用量，默认1g\n",
    "\t(\"spark.master\", SPARK_URL),    # spark master的地址\n",
    "    (\"spark.executor.cores\", \"2\"),   # 设置spark executor使用的CPU核心数\n",
    "    (\"spark.executor.instances\", 1)    # 设置spark executor数量，yarn时起作用\n",
    ")\n",
    "# 查看更详细配置及说明：https://spark.apache.org/docs/latest/configuration.html\n",
    "# \n",
    "conf.setAll(config)\n",
    "\n",
    "# 利用config对象，创建spark session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集：\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "|affairs|age|religiousness|education|occupation|rating|            features|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "|      0| 37|            3|       18|         7|     4|[37.0,3.0,18.0,7....|\n",
      "|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|\n",
      "|      0| 32|            1|       12|         1|     4|[32.0,1.0,12.0,1....|\n",
      "|      0| 57|            5|       18|         6|     5|[57.0,5.0,18.0,6....|\n",
      "|      0| 22|            2|       17|         6|     3|[22.0,2.0,17.0,6....|\n",
      "|      0| 32|            2|       17|         5|     5|[32.0,2.0,17.0,5....|\n",
      "|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|\n",
      "|      0| 57|            2|       14|         4|     4|[57.0,2.0,14.0,4....|\n",
      "|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|\n",
      "|      0| 22|            4|       14|         4|     5|[22.0,4.0,14.0,4....|\n",
      "|      0| 37|            2|       20|         7|     2|[37.0,2.0,20.0,7....|\n",
      "|      0| 27|            4|       18|         6|     4|[27.0,4.0,18.0,6....|\n",
      "|      0| 47|            5|       17|         6|     4|[47.0,5.0,17.0,6....|\n",
      "|      0| 22|            2|       17|         5|     4|[22.0,2.0,17.0,5....|\n",
      "|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|\n",
      "|      0| 37|            1|       17|         5|     5|[37.0,1.0,17.0,5....|\n",
      "|      0| 37|            2|       18|         4|     3|[37.0,2.0,18.0,4....|\n",
      "|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|\n",
      "|      0| 22|            2|       16|         5|     5|[22.0,2.0,16.0,5....|\n",
      "|      0| 27|            2|       14|         1|     5|[27.0,2.0,14.0,1....|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "训练集：\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "|affairs|age|religiousness|education|occupation|rating|            features|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "|      0| 32|            1|       12|         1|     4|[32.0,1.0,12.0,1....|\n",
      "|      0| 37|            3|       18|         7|     4|[37.0,3.0,18.0,7....|\n",
      "|      0| 22|            2|       17|         6|     3|[22.0,2.0,17.0,6....|\n",
      "|      0| 32|            2|       17|         5|     5|[32.0,2.0,17.0,5....|\n",
      "|      0| 57|            5|       18|         6|     5|[57.0,5.0,18.0,6....|\n",
      "|      0| 57|            2|       14|         4|     4|[57.0,2.0,14.0,4....|\n",
      "|      0| 22|            2|       17|         5|     4|[22.0,2.0,17.0,5....|\n",
      "|      0| 22|            4|       14|         4|     5|[22.0,4.0,14.0,4....|\n",
      "|      0| 27|            4|       18|         6|     4|[27.0,4.0,18.0,6....|\n",
      "|      0| 37|            2|       20|         7|     2|[37.0,2.0,20.0,7....|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "测试集：\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "|affairs|age|religiousness|education|occupation|rating|            features|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|\n",
      "|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|\n",
      "|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|\n",
      "|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|\n",
      "|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|\n",
      "|      1| 27|            4|       16|         1|     2|[27.0,4.0,16.0,1....|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "\n",
    "# 样本数据集\n",
    "sample_dataset = [\n",
    "    (0, \"male\", 37, 10, \"no\", 3, 18, 7, 4),\n",
    "    (0, \"female\", 27, 4, \"no\", 4, 14, 6, 4),\n",
    "    (0, \"female\", 32, 15, \"yes\", 1, 12, 1, 4),\n",
    "    (0, \"male\", 57, 15, \"yes\", 5, 18, 6, 5),\n",
    "    (0, \"male\", 22, 0.75, \"no\", 2, 17, 6, 3),\n",
    "    (0, \"female\", 32, 1.5, \"no\", 2, 17, 5, 5),\n",
    "    (0, \"female\", 22, 0.75, \"no\", 2, 12, 1, 3),\n",
    "    (0, \"male\", 57, 15, \"yes\", 2, 14, 4, 4),\n",
    "    (0, \"female\", 32, 15, \"yes\", 4, 16, 1, 2),\n",
    "    (0, \"male\", 22, 1.5, \"no\", 4, 14, 4, 5),\n",
    "    (0, \"male\", 37, 15, \"yes\", 2, 20, 7, 2),\n",
    "    (0, \"male\", 27, 4, \"yes\", 4, 18, 6, 4),\n",
    "    (0, \"male\", 47, 15, \"yes\", 5, 17, 6, 4),\n",
    "    (0, \"female\", 22, 1.5, \"no\", 2, 17, 5, 4),\n",
    "    (0, \"female\", 27, 4, \"no\", 4, 14, 5, 4),\n",
    "    (0, \"female\", 37, 15, \"yes\", 1, 17, 5, 5),\n",
    "    (0, \"female\", 37, 15, \"yes\", 2, 18, 4, 3),\n",
    "    (0, \"female\", 22, 0.75, \"no\", 3, 16, 5, 4),\n",
    "    (0, \"female\", 22, 1.5, \"no\", 2, 16, 5, 5),\n",
    "    (0, \"female\", 27, 10, \"yes\", 2, 14, 1, 5),\n",
    "    (1, \"female\", 32, 15, \"yes\", 3, 14, 3, 2),\n",
    "    (1, \"female\", 27, 7, \"yes\", 4, 16, 1, 2),\n",
    "    (1, \"male\", 42, 15, \"yes\", 3, 18, 6, 2),\n",
    "    (1, \"female\", 42, 15, \"yes\", 2, 14, 3, 2),\n",
    "    (1, \"male\", 27, 7, \"yes\", 2, 17, 5, 4),\n",
    "    (1, \"male\", 32, 10, \"yes\", 4, 14, 4, 3),\n",
    "    (1, \"male\", 47, 15, \"yes\", 3, 16, 4, 2),\n",
    "    (0, \"male\", 37, 4, \"yes\", 2, 20, 6, 4)\n",
    "]\n",
    "\n",
    "columns = [\"affairs\", \"gender\", \"age\", \"label\", \"children\", \"religiousness\", \"education\", \"occupation\", \"rating\"]\n",
    "\n",
    "# pandas构建dataframe，方便\n",
    "pdf = pd.DataFrame(sample_dataset, columns=columns)\n",
    "\n",
    "# 转换成spark的dataframe\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# 特征选取：affairs为目标值，其余为特征值\n",
    "df2 = df.select(\"affairs\",\"age\", \"religiousness\", \"education\", \"occupation\", \"rating\")\n",
    "\n",
    "# 用于计算特征向量的字段\n",
    "colArray2 = [\"age\", \"religiousness\", \"education\", \"occupation\", \"rating\"]\n",
    "\n",
    "# 计算出特征向量\n",
    "df3 = VectorAssembler().setInputCols(colArray2).setOutputCol(\"features\").transform(df2)\n",
    "print(\"数据集：\")\n",
    "df3.show()\n",
    "\n",
    "#  随机切分为训练集和测试集\n",
    "trainDF, testDF = df3.randomSplit([0.8,0.2])\n",
    "print(\"训练集：\")\n",
    "trainDF.show(10)\n",
    "print(\"测试集：\")\n",
    "testDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [逻辑回归分类器-pyspark.ml.classification.LogisticRegression](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegression)\n",
    "#### [逻辑回归分类模型-pyspark.ml.classification.LogisticRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegressionModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+\n",
      "|affairs|age|religiousness|education|occupation|rating|            features|       rawPrediction|         probability|prediction|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+\n",
      "|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|[0.39067871041193...|[0.59644607432863...|       0.0|\n",
      "|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|[-2.6754687573263...|[0.06443650129497...|       1.0|\n",
      "|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|[-4.5240336812732...|[0.01072883305878...|       1.0|\n",
      "|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|[0.16206512668426...|[0.54042783360658...|       0.0|\n",
      "|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|[1.69102697292197...|[0.84435916906682...|       0.0|\n",
      "|      1| 27|            4|       16|         1|     2|[27.0,4.0,16.0,1....|[-4.7969907272012...|[0.00818697014985...|       1.0|\n",
      "+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "# 创建逻辑回归训练器\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 训练模型\n",
    "model = lr.setLabelCol(\"affairs\").setFeaturesCol(\"features\").fit(trainDF)\n",
    "\n",
    "# 预测数据\n",
    "model.transform(testDF).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
